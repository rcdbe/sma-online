{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic_Modelling.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcdbe/sma-online/blob/master/day-3/Topic_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCCukGszFWPL",
        "colab_type": "text"
      },
      "source": [
        "*Social Media Analytics Worskhop - Telkom University*\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG-faJjnRuDS",
        "colab_type": "text"
      },
      "source": [
        "# Topic Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC8fK2kzfW4j",
        "colab_type": "text"
      },
      "source": [
        "Topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body. Intuitively, given that a document is about a particular topic, one would expect particular words to appear in the document more or less frequently: \"dog\" and \"bone\" will appear more often in documents about dogs, \"cat\" and \"meow\" will appear in documents about cats, and \"the\" and \"is\" will appear equally in both. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxM8QfGWRt0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Library\n",
        "! pip install pyLDAvis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LTY4ilBSCdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Libraries\n",
        "import nltk\n",
        "import os\n",
        "import numpy as np, pyLDAvis, pyLDAvis.sklearn; pyLDAvis.enable_notebook()\n",
        "\n",
        "# Import Modules\n",
        "from __future__ import print_function \n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSkNONYpSEXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone Library and Data from Github\n",
        "! git clone https://github.com/rcdbe/sma-online"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKBJMDD0kcjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Data Directory\n",
        "os.chdir('sma-online/day-3/Source')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysp9aWhzSUuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Stop Words\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Import Data\n",
        "data_file = 'berita_batubara.csv'\n",
        "\n",
        "# Load Tweets Data\n",
        "import MyLib as TS\n",
        "Tweets = TS.LoadTxt(data_file) \n",
        "print('Total loaded tweets = {0}'.format(len(Tweets)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK4J4At2gRwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_topics = 4\n",
        "top_topics = 4\n",
        "top_words = 8\n",
        "max_df = 0.75\n",
        "min_df = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w25SADrrPf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Extraction (Word Embedding)\n",
        "count_vector = CountVectorizer(lowercase = True, token_pattern = r'\\b[a-zA-Z]{3,}\\b',max_df = max_df, min_df = min_df) \n",
        "dtm_tf = count_vector.fit_transform(Tweets)\n",
        "tf_terms = count_vector.get_feature_names()\n",
        "del Tweets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcMlhTzUuyrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Topic Search Function\n",
        "lda_tf = LatentDirichletAllocation(n_components=n_topics, learning_method='online', random_state=0).fit(dtm_tf)\n",
        "\n",
        "# Show Topics\n",
        "vsm_topics = lda_tf.transform(dtm_tf); doc_topic =  [a.argmax()+1 for a in tqdm(vsm_topics)] # topic of docs\n",
        "print('In total there are {0} major topics, distributed as follows'.format(len(set(doc_topic))))\n",
        "plt.hist(np.array(doc_topic), alpha=0.5); plt.show()\n",
        "print('Printing top {0} Topics, with top {1} Words:'.format(top_topics, top_words))\n",
        "TS.print_Topics(lda_tf, tf_terms, top_topics, top_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRG28QyXYPwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interactively visualizing the Topics, please ignore the Warnings\n",
        "# Wait few minutes and then hover the Mouse over the Topics to Explore\n",
        "pyLDAvis.sklearn.prepare(lda_tf, dtm_tf, count_vector) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}