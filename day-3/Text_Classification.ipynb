{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcdbe/sma-online/blob/master/day-3/Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWlK4zxdFPO4",
        "colab_type": "text"
      },
      "source": [
        "*Social Media Analytics Worskhop - Telkom University*\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g6UaT0G--xh",
        "colab_type": "text"
      },
      "source": [
        "# Text Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVNV4kIvApmh",
        "colab_type": "text"
      },
      "source": [
        "Text classification is the process of assigning tags or categories to text according to its content. Itâ€™s one of the fundamental tasks in Natural Language Processing (NLP) with broad applications such as sentiment analysis, topic labeling, spam detection, and intent detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQGyxU9XAepj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Library\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67KZ1JdiLJOs",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4zrKHV5aot-",
        "colab_type": "text"
      },
      "source": [
        "Sentiment analysis is the interpretation and classification of emotions (positive, negative and neutral) within text data using text analysis techniques. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFm6XrjOkRVW",
        "colab_type": "text"
      },
      "source": [
        "### Predefined Model (Only English)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ubIBzkhjQdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Library\n",
        "! pip install vaderSentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw3chc-Lkwl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Module\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wROE6eyskye8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Sentiment Analysis Function\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "def sentiment_analyzer_scores(sentence):\n",
        "    score = analyzer.polarity_scores(sentence)\n",
        "    print(\"{:-<40} {}\".format(sentence, str(score)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWK2Ve-2a4xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input English Text\n",
        "text_en = 'The death toll from the coronavirus has reached 28 in South Korea with 600 newly confirmed cases, raising the national Itally to 4,812 cases, the South Korean Centers for Disease Control and Prevention (KCDC) said in a news release Tuesday.'\n",
        "text_en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFsqJCRok45k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Detect the Text Sentiment\n",
        "sentiment_analyzer_scores(text_en)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTVpdAnjjdm1",
        "colab_type": "text"
      },
      "source": [
        "### Train New Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9LpvI8C1tCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Library\n",
        "import pandas as pd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp1rO_upbh88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Modules\n",
        "from sklearn.feature_extraction.text import CountVectorizer # to create Bag of words\n",
        "from sklearn.model_selection import train_test_split  # for splitting data\n",
        "from sklearn.naive_bayes import GaussianNB # to bulid classifier model\n",
        "from sklearn.preprocessing import LabelEncoder # to convert classes to number \n",
        "from sklearn.metrics import accuracy_score # to calculate accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daJA40gOX31_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Train Data\n",
        "df_grab = pd.read_csv('https://raw.githubusercontent.com/rcdbe/sma-online/master/day-3/Source/grab-tweet.csv', sep = ';')\n",
        "df_grab.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ6nleQKZ5oW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count the Sentiment\n",
        "df_grab.sentiment.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51qqAfQyfFHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Extraction (Word Embedding)\n",
        "count_vector = CountVectorizer(max_features = 1500)  \n",
        "grab_feature = count_vector.fit_transform(df_grab['text']).toarray() \n",
        "grab_feature_matrix = pd.DataFrame(grab_feature,columns=count_vector.get_feature_names())\n",
        "grab_feature_matrix.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zChazFSYaXjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Target\n",
        "encoder = LabelEncoder()\n",
        "grab_label = encoder.fit_transform(df_grab['sentiment'])\n",
        "grab_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mANHXjUbci5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Training and Testing Data (70:30)\n",
        "feature_train, feature_test, target_train, target_test = train_test_split(grab_feature, grab_label, shuffle = True, test_size=0.3, random_state=1)\n",
        "\n",
        "# Show the Training and Testing Data\n",
        "print(feature_train.shape)\n",
        "print(feature_test.shape)\n",
        "print(target_train.shape)\n",
        "print(target_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqPt1xamaldd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Naive Bayes Model\n",
        "nb = GaussianNB().fit(feature_train, target_train)\n",
        "\n",
        "# Predict to Test Data\n",
        "target_predicted = nb.predict(feature_test) \n",
        "target_predicted "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqMIi9tRaqkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Test model accuracy: ',accuracy_score(target_test, target_predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R8odXorasuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input New Statement\n",
        "new_statement = ['saya suka grab'] \n",
        "\n",
        "# Extract Features\n",
        "new_statement_features = count_vector.transform(new_statement).toarray()\n",
        "\n",
        "## encodeing predict class\n",
        "predict_sentiment = encoder.inverse_transform(nb.predict(new_statement_features))\n",
        "print(new_statement[0], 'sentiment: ',predict_sentiment[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlKRyvqHLbC1",
        "colab_type": "text"
      },
      "source": [
        "## Hate Speech Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBx871ZKb5Yu",
        "colab_type": "text"
      },
      "source": [
        "This aims to classify textual content into non-hate or hate speech, in which case the method may also identify the targeting characteristics (i.e., types of hate, such as race, and religion) in the hate speech."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFqHF-n1cBl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Library\n",
        "import pandas as pd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_noa61NNcIcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Modules\n",
        "from sklearn.feature_extraction.text import CountVectorizer # to create Bag of words\n",
        "from sklearn.model_selection import train_test_split  # for splitting data\n",
        "from sklearn.naive_bayes import GaussianNB # to bulid classifier model\n",
        "from sklearn.preprocessing import LabelEncoder # to convert classes to number \n",
        "from sklearn.metrics import accuracy_score # to calculate accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMkJBK83Lo-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_hs = pd.read_csv('https://raw.githubusercontent.com/rcdbe/sma-online/master/day-3/Source/data_hs.csv', sep = \";\")\n",
        "df_hs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpELpIr_TZL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count of each type \n",
        "df_hs.label.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_JLPlTvcfU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Extraction (Word Embedding)\n",
        "count_vector = CountVectorizer(max_features = 1500)  \n",
        "hs_feature = count_vector.fit_transform(df_hs['text']).toarray() \n",
        "hs_feature_matrix = pd.DataFrame(hs_feature,columns=count_vector.get_feature_names())\n",
        "hs_feature_matrix.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYVTn70TdGLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Target\n",
        "encoder = LabelEncoder()\n",
        "hs_label = encoder.fit_transform(df_hs['label'])\n",
        "hs_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8qpwGHRdun3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Training and Testing Data (70:30)\n",
        "feature_train, feature_test, target_train, target_test = train_test_split(hs_feature, hs_label, shuffle = True, test_size=0.3, random_state=1)\n",
        "\n",
        "# Show the Training and Testing Data\n",
        "print(feature_train.shape)\n",
        "print(feature_test.shape)\n",
        "print(target_train.shape)\n",
        "print(target_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arm-4x6kUSpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Naive Bayes Model\n",
        "nb = GaussianNB().fit(feature_train, target_train)\n",
        "\n",
        "# Predict to Test Data\n",
        "target_predicted = nb.predict(feature_test) \n",
        "target_predicted "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AoKrQYCUX5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Test model accuracy: ',accuracy_score(target_test, target_predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-sxG7CyUZbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input New Statement\n",
        "new_statement = ['Ku Cinta Dia'] \n",
        "\n",
        "# Extract Features\n",
        "new_statement_features = count_vector.transform(new_statement).toarray()\n",
        "\n",
        "## encodeing predict class\n",
        "predict_label = encoder.inverse_transform(nb.predict(new_statement_features))\n",
        "print(new_statement[0], 'sentiment: ',predict_label[0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}