{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Network_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcdbe/sma-online/blob/master/day-3/Text_Network_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW0gNBkTv76P",
        "colab_type": "text"
      },
      "source": [
        "*Social Media Analytics Worskhop - Telkom University*\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KQyo0z5wPXn",
        "colab_type": "text"
      },
      "source": [
        "# Text Network Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxy3j3UGzaO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Library\n",
        "import numpy as np\n",
        "import nltk\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from nltk import bigrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from random import seed\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlNzgRLNGbd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Seed\n",
        "seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCjhYgD2iu39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/sma-workshop/r/master/data/processed/berita-batubara.csv')\n",
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A48ctKncxohk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select Text\n",
        "text = df['text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69iDb0mFz9an",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize\n",
        "text_data = [word_tokenize(i) for i in text]\n",
        "print(text_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K92iTqurzfN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Fuction to show co occurrence\n",
        "def generate_co_occurrence_matrix(corpus):\n",
        "    vocab = set(corpus)\n",
        "    vocab = list(vocab)\n",
        "    vocab_index = {word: i for i, word in enumerate(vocab)}\n",
        " \n",
        "    # Create bigrams from all words in corpus\n",
        "    bi_grams = list(bigrams(corpus))\n",
        " \n",
        "    # Frequency distribution of bigrams ((word1, word2), num_occurrences)\n",
        "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
        " \n",
        "    # Initialise co-occurrence matrix\n",
        "    # co_occurrence_matrix[current][previous]\n",
        "    co_occurrence_matrix = np.zeros((len(vocab), len(vocab)))\n",
        " \n",
        "    # Loop through the bigrams taking the current and previous word,\n",
        "    # and the number of occurrences of the bigram.\n",
        "    for bigram in bigram_freq:\n",
        "        current = bigram[0][1]\n",
        "        previous = bigram[0][0]\n",
        "        count = bigram[1]\n",
        "        pos_current = vocab_index[current]\n",
        "        pos_previous = vocab_index[previous]\n",
        "        co_occurrence_matrix[pos_current][pos_previous] = count\n",
        "    co_occurrence_matrix = np.matrix(co_occurrence_matrix)\n",
        " \n",
        "    # return the matrix and the index\n",
        "    return co_occurrence_matrix, vocab_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAQ6O19Mzjdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create one list using many lists\n",
        "data = list(itertools.chain.from_iterable(text_data))\n",
        "matrix, vocab_index = generate_co_occurrence_matrix(data)\n",
        " \n",
        " \n",
        "data_matrix = pd.DataFrame(matrix, index=vocab_index,\n",
        "                             columns=vocab_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84Fr-wn84VuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show Matrix\n",
        "data_matrix.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JAZLBpg4ny0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save matrix as CSV, so we can analyze it Gephi\n",
        "data_matrix.to_csv('matrix.csv', encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbNPTWdWyLcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to Edge List\n",
        "edgelist = nx.to_pandas_edgelist(G)\n",
        "edgelist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih7sM4lZ4nTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create sample since the real data is too big. \n",
        "sample = edgelist.sample(10)\n",
        "sample.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqlDo1Kj5RHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Contstruct a Network\n",
        "G = nx.from_pandas_edgelist(sample)\n",
        "\n",
        "# Visualize the Network\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,10))\n",
        "nx.draw(G, with_labels=True, \n",
        "        node_color='skyblue', node_size=1200, \n",
        "        arrowstyle='->',arrowsize=20, edge_color='r',\n",
        "        font_size=9,\n",
        "        pos=nx.kamada_kawai_layout(G))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}