{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "007_text_mining_part_2_(tc&tm).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDiwU2gV_eRY",
        "colab_type": "text"
      },
      "source": [
        "# Text Mining Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-qyukn5AbJ6",
        "colab_type": "text"
      },
      "source": [
        "After we pre-process the text, we can perform text mining in a better condition. Here we will do text classification and topic modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1XIUk-VAY7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Library\n",
        "!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQGyxU9XAepj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Library\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYtibotwXwTe",
        "colab_type": "text"
      },
      "source": [
        "## **1. Text Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVNV4kIvApmh",
        "colab_type": "text"
      },
      "source": [
        "Text classification is the process of assigning tags or categories to text according to its content. Itâ€™s one of the fundamental tasks in Natural Language Processing (NLP) with broad applications such as sentiment analysis, topic labeling, spam detection, and intent detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67KZ1JdiLJOs",
        "colab_type": "text"
      },
      "source": [
        "#### **1.1. Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4zrKHV5aot-",
        "colab_type": "text"
      },
      "source": [
        "Sentiment analysis is the interpretation and classification of emotions (positive, negative and neutral) within text data using text analysis techniques. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFm6XrjOkRVW",
        "colab_type": "text"
      },
      "source": [
        "##### **a. Using Predefined Model (Only English)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA3pmfnoqeu6",
        "colab_type": "text"
      },
      "source": [
        "***Install Library and Import Module***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ubIBzkhjQdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Library\n",
        "! pip install vaderSentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw3chc-Lkwl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Module\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dxFaR5hq-e_",
        "colab_type": "text"
      },
      "source": [
        "***Create Sentiment Analysis Function***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wROE6eyskye8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Sentiment Analysis Function\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "def sentiment_analyzer_scores(sentence):\n",
        "    score = analyzer.polarity_scores(sentence)\n",
        "    print(\"{:-<40} {}\".format(sentence, str(score)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRqhpJBwrMWs",
        "colab_type": "text"
      },
      "source": [
        "***Detect the Text Sentiment***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWK2Ve-2a4xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input English Text\n",
        "text_en = 'The death toll from the coronavirus has reached 28 in South Korea with 600 newly confirmed cases, raising the national Itally to 4,812 cases, the South Korean Centers for Disease Control and Prevention (KCDC) said in a news release Tuesday.'\n",
        "text_en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFsqJCRok45k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Detect the Text Sentiment\n",
        "sentiment_analyzer_scores(text_en)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTVpdAnjjdm1",
        "colab_type": "text"
      },
      "source": [
        "##### **b. Using Machine Learning Principle (Customizable)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS1tn24rbHtV",
        "colab_type": "text"
      },
      "source": [
        "***Import Library and Modules***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9LpvI8C1tCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Library\n",
        "import pandas as pd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp1rO_upbh88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Modules\n",
        "from sklearn.feature_extraction.text import CountVectorizer # to create Bag of words\n",
        "from sklearn.model_selection import train_test_split  # for splitting data\n",
        "from sklearn.naive_bayes import GaussianNB # to bulid classifier model\n",
        "from sklearn.preprocessing import LabelEncoder # to convert classes to number \n",
        "from sklearn.metrics import accuracy_score # to calculate accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "catA6W8TsmrS",
        "colab_type": "text"
      },
      "source": [
        "***Import Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daJA40gOX31_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Train Data\n",
        "df_grab = pd.read_csv('https://raw.githubusercontent.com/dhitology/temporary/master/grab-tweet.csv', sep = ';')\n",
        "df_grab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ6nleQKZ5oW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count the Sentiment\n",
        "df_grab.sentiment.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTG1MbTislnz",
        "colab_type": "text"
      },
      "source": [
        "***Set Feature and Target***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVGGxrHie8YI",
        "colab_type": "text"
      },
      "source": [
        "Set Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51qqAfQyfFHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Extraction (Word Embedding)\n",
        "count_vector = CountVectorizer(max_features = 1500)  \n",
        "grab_feature = count_vector.fit_transform(df_grab['text']).toarray() \n",
        "grab_feature_matrix = pd.DataFrame(grab_feature,columns=count_vector.get_feature_names())\n",
        "grab_feature_matrix.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBKIxZEJhFE-",
        "colab_type": "text"
      },
      "source": [
        "Set Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zChazFSYaXjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Target\n",
        "encoder = LabelEncoder()\n",
        "grab_label = encoder.fit_transform(df_grab['sentiment'])\n",
        "grab_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsE5LQtZb-2i",
        "colab_type": "text"
      },
      "source": [
        "***Set Training and Testing Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mANHXjUbci5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Training and Testing Data (70:30)\n",
        "feature_train, feature_test, target_train, target_test = train_test_split(grab_feature, grab_label, shuffle = True, test_size=0.3, random_state=1)\n",
        "\n",
        "# Show the Training and Testing Data\n",
        "print(feature_train.shape)\n",
        "print(feature_test.shape)\n",
        "print(target_train.shape)\n",
        "print(target_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddUQudp9i_iT",
        "colab_type": "text"
      },
      "source": [
        "***Construct Naive Bayes Sentiment Classifier***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqPt1xamaldd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Naive Bayes Model\n",
        "nb = GaussianNB().fit(feature_train, target_train)\n",
        "\n",
        "# Predict to Test Data\n",
        "target_predicted = nb.predict(feature_test) \n",
        "target_predicted "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGkBRU7ekBWx",
        "colab_type": "text"
      },
      "source": [
        "***Show Accuration***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqMIi9tRaqkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Test model accuracy: ',accuracy_score(target_test, target_predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jGQYdXRRQsg",
        "colab_type": "text"
      },
      "source": [
        "***Predict Sentiment***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R8odXorasuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input New Statement\n",
        "new_statement = ['saya tidak suka grab'] \n",
        "\n",
        "# Extract Features\n",
        "new_statement_features = count_vector.transform(new_statement).toarray()\n",
        "\n",
        "## encodeing predict class\n",
        "predict_sentiment = encoder.inverse_transform(nb.predict(new_statement_features))\n",
        "print(new_statement[0], 'sentiment: ',predict_sentiment[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlKRyvqHLbC1",
        "colab_type": "text"
      },
      "source": [
        "#### **1.2. Hate Speech Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBx871ZKb5Yu",
        "colab_type": "text"
      },
      "source": [
        "This aims to classify textual content into non-hate or hate speech, in which case the method may also identify the targeting characteristics (i.e., types of hate, such as race, and religion) in the hate speech."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDhOajribpz9",
        "colab_type": "text"
      },
      "source": [
        "***Import Library and Modules***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFqHF-n1cBl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Library\n",
        "import pandas as pd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_noa61NNcIcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Modules\n",
        "from sklearn.feature_extraction.text import CountVectorizer # to create Bag of words\n",
        "from sklearn.model_selection import train_test_split  # for splitting data\n",
        "from sklearn.naive_bayes import GaussianNB # to bulid classifier model\n",
        "from sklearn.preprocessing import LabelEncoder # to convert classes to number \n",
        "from sklearn.metrics import accuracy_score # to calculate accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmYlUdpOcNgC",
        "colab_type": "text"
      },
      "source": [
        "***Import Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMkJBK83Lo-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_hs = pd.read_csv('https://raw.githubusercontent.com/dhitology/temporary/master/data_hs.csv', sep = \";\")\n",
        "df_hs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpELpIr_TZL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count of each type \n",
        "df_hs.label.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNR3fynWcQ3-",
        "colab_type": "text"
      },
      "source": [
        "***Set Feature and Target***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwvgOarjdBwo",
        "colab_type": "text"
      },
      "source": [
        "Set Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_JLPlTvcfU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Extraction (Word Embedding)\n",
        "count_vector = CountVectorizer(max_features = 1500)  \n",
        "hs_feature = count_vector.fit_transform(df_hs['text']).toarray() \n",
        "hs_feature_matrix = pd.DataFrame(hs_feature,columns=count_vector.get_feature_names())\n",
        "hs_feature_matrix.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5uyikpZdEkk",
        "colab_type": "text"
      },
      "source": [
        "Set Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYVTn70TdGLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Target\n",
        "encoder = LabelEncoder()\n",
        "hs_label = encoder.fit_transform(df_hs['label'])\n",
        "hs_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4Rf0Qe_dF8S",
        "colab_type": "text"
      },
      "source": [
        "***Set Training and Testing Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8qpwGHRdun3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Training and Testing Data (70:30)\n",
        "feature_train, feature_test, target_train, target_test = train_test_split(hs_feature, hs_label, shuffle = True, test_size=0.3, random_state=1)\n",
        "\n",
        "# Show the Training and Testing Data\n",
        "print(feature_train.shape)\n",
        "print(feature_test.shape)\n",
        "print(target_train.shape)\n",
        "print(target_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KClg0opcd7Jt",
        "colab_type": "text"
      },
      "source": [
        "***Construct Naive Bayes Sentiment Classifier***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arm-4x6kUSpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Naive Bayes Model\n",
        "nb = GaussianNB().fit(feature_train, target_train)\n",
        "\n",
        "# Predict to Test Data\n",
        "target_predicted = nb.predict(feature_test) \n",
        "target_predicted "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed6GFtiHeHlI",
        "colab_type": "text"
      },
      "source": [
        "***Show Accuration***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AoKrQYCUX5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Test model accuracy: ',accuracy_score(target_test, target_predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABDZVjGoeXon",
        "colab_type": "text"
      },
      "source": [
        "***Predict Label***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-sxG7CyUZbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input New Statement\n",
        "new_statement = ['Dia Bangsat Perusak Negara'] \n",
        "\n",
        "# Extract Features\n",
        "new_statement_features = count_vector.transform(new_statement).toarray()\n",
        "\n",
        "## encodeing predict class\n",
        "predict_label = encoder.inverse_transform(nb.predict(new_statement_features))\n",
        "print(new_statement[0], 'sentiment: ',predict_label[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG-faJjnRuDS",
        "colab_type": "text"
      },
      "source": [
        "## **2. Topic Modelling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC8fK2kzfW4j",
        "colab_type": "text"
      },
      "source": [
        "Topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body. Intuitively, given that a document is about a particular topic, one would expect particular words to appear in the document more or less frequently: \"dog\" and \"bone\" will appear more often in documents about dogs, \"cat\" and \"meow\" will appear in documents about cats, and \"the\" and \"is\" will appear equally in both. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG2t_7n6fawH",
        "colab_type": "text"
      },
      "source": [
        "***Install Library, Import Libraries, and Import Modules***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxM8QfGWRt0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Library\n",
        "! pip install pyLDAvis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LTY4ilBSCdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Libraries\n",
        "import nltk\n",
        "import os\n",
        "import numpy as np, pyLDAvis, pyLDAvis.sklearn; pyLDAvis.enable_notebook()\n",
        "\n",
        "# Import Modules\n",
        "from __future__ import print_function \n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSkNONYpSEXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone Library and Data from Github\n",
        "! git clone https://github.com/dianrdn/tm\n",
        "\n",
        "# Set Data Directory\n",
        "os.chdir('tm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2McCxJ8CgI4y",
        "colab_type": "text"
      },
      "source": [
        "***Import Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysp9aWhzSUuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Stop Words\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Import Data\n",
        "data_file = 'berita_batubara.csv'\n",
        "\n",
        "# Load Tweets Data\n",
        "import MyLib as TS\n",
        "Tweets = TS.LoadTxt(data_file) \n",
        "print('Total loaded tweets = {0}'.format(len(Tweets)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdDudz3lgWy4",
        "colab_type": "text"
      },
      "source": [
        "***Set Number of Topics, Top Topics, Top Words, Max DF, Min DF***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK4J4At2gRwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_topics = 4\n",
        "top_topics = 4\n",
        "top_words = 8\n",
        "max_df = 0.75\n",
        "min_df = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AL5bu8Tld7S",
        "colab_type": "text"
      },
      "source": [
        "***Word Embedding***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w25SADrrPf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Extraction (Word Embedding)\n",
        "count_vector = CountVectorizer(lowercase = True, token_pattern = r'\\b[a-zA-Z]{3,}\\b',max_df = max_df, min_df = min_df) \n",
        "dtm_tf = count_vector.fit_transform(Tweets)\n",
        "tf_terms = count_vector.get_feature_names()\n",
        "del Tweets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aS5jGV0up2p",
        "colab_type": "text"
      },
      "source": [
        "***Show Topic***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcMlhTzUuyrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Topic Search Function\n",
        "lda_tf = LatentDirichletAllocation(n_components=n_topics, learning_method='online', random_state=0).fit(dtm_tf)\n",
        "\n",
        "# Show Topics\n",
        "vsm_topics = lda_tf.transform(dtm_tf); doc_topic =  [a.argmax()+1 for a in tqdm(vsm_topics)] # topic of docs\n",
        "print('In total there are {0} major topics, distributed as follows'.format(len(set(doc_topic))))\n",
        "plt.hist(np.array(doc_topic), alpha=0.5); plt.show()\n",
        "print('Printing top {0} Topics, with top {1} Words:'.format(top_topics, top_words))\n",
        "TS.print_Topics(lda_tf, tf_terms, top_topics, top_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRG28QyXYPwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interactively visualizing the Topics, please ignore the Warnings\n",
        "# Wait few minutes and then hover the Mouse over the Topics to Explore\n",
        "pyLDAvis.sklearn.prepare(lda_tf, dtm_tf, count_vector) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}